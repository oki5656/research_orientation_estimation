# research_orientation_estimation
本リポジトリは，次歩推定の学習や学習結果のvisualizeが可能となっている．  

## installation
#### 動作確認環境
python  == 3.7
（動作確認済み2023/3/17）  

#### 必要ライブラリ
matplotlib==3.5.3  
numpy==1.21.6  
opencv-python==4.6.0.66  
optuna==3.0.3  
pandas==1.3.5  
scipy==1.7.3  
torch==1.12.1+cu113  
torchaudio==0.12.1+cu113  
torchvision==0.13.1+cu113  
tqdm==4.64.1  

## Dataset
データセットはラージスペースのモーションキャプチャシステムにより自作した，歩行軌跡とスマートフォンの慣性データを含む（詳しくは修論参照）データを用いる．  
以前は，TUMやoxford_IODデータセットによる学習も行っていたがバージョンの更新により現在は未動作確認．

## Train
open_dataset/codes/train.pyを使用することでtrain, validation, testが一度に可能．  
optunaにより例えば100エポックの学習に対して任意のトライアル数を設定することができハイパラの調整が可能となる．本リポジトリに保存されているコードではトライアル数は25に設定してある．
結果は指定したディレクトリに自動的の保存される．保存される内容は，学習曲線，最後の5エポックの平均結果，各々のトライアルの最後のエポックの結果，テストデータによる結果，トライアルごとのハイパラ，重みファイルである．なお本学習における結果とは平均絶対角度誤差，平均絶対距離誤差，学習におけるlossの3種類である．

## Test
・test.py : 学習におけるtest工程のみを行うことができる．
・test_draw_next_step_result.py : スマートフォン座標系における物体の位置が，画像上の想定する位置に描画されるかを確かめることが可能．
・test_predict.py : このファイルは学習モデルの出力を確かめたり，処理時間を計測するために用いる.

## Visualize
本リポジトリではいくつかのファイルにより，次歩推定結果のvisualizeが可能となっている．
・draw_next_step_result.py : スマートフォンにより集計したIMUの時系列データと，可視光カメラによる映像を用いることで，映像中に次歩推定ベクトルを描画することが可能である．ただし実際の出力は複数の画像であり動画ではない．
・predict_draw_trajectry.py : 学習用データを用いることで，次歩推定位置と次歩正解位置の移動軌跡を描画することができる．
・make_video_from_imgs.py : draw_next_step_result.pyにより生成した画像をつなぎ合わせて動画を作成することができる．
